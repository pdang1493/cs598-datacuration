{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2a3c09b-1515-4020-8d7f-3b11cd5f7f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis script performs data cleaning on the NYPL Menu dataset fields:\\n    - place\\n    - event\\n    - sponsor\\n    - venue\\n\\nCleaning steps include:\\n    - Removing noise characters (e.g., brackets, quotes, punctuation)\\n    - Correcting typos and standardizing text\\n    - Normalizing whitespace\\n    - Handling null or blank values\\n    - Converting to uppercase for consistency\\n\\nCleaned fields are saved in new columns:\\n    - place_cleaned\\n    - event_cleaned\\n    - sponsor_cleaned\\n    - venue_cleaned\\n\\nFinal output is saved to Menu_cleaned.csv\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script performs data cleaning on the NYPL Menu dataset fields:\n",
    "    - place\n",
    "    - event\n",
    "    - sponsor\n",
    "    - venue\n",
    "\n",
    "Cleaning steps include:\n",
    "    - Removing noise characters (e.g., brackets, quotes, punctuation)\n",
    "    - Correcting typos and standardizing text\n",
    "    - Normalizing whitespace\n",
    "    - Handling null or blank values\n",
    "    - Converting to uppercase for consistency\n",
    "\n",
    "Cleaned fields are saved in new columns:\n",
    "    - place_cleaned\n",
    "    - event_cleaned\n",
    "    - sponsor_cleaned\n",
    "    - venue_cleaned\n",
    "\n",
    "Final output is saved to Menu_cleaned.csv\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "471755ab-fba8-42fa-9277-188eda08aeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved as Menu_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"Menu.csv\")\n",
    "\n",
    "# Full dictionary to standardize U.S. state names\n",
    "state_abbrev_fixes = {\n",
    "    'ALA': 'AL', 'ALABAMA': 'AL',\n",
    "    'ALASKA': 'AK',\n",
    "    'ARIZ': 'AZ', 'ARIZONA': 'AZ',\n",
    "    'ARK': 'AR', 'ARKANSAS': 'AR',\n",
    "    'CALIF': 'CA', 'CALIFORNIA': 'CA',\n",
    "    'COLO': 'CO', 'COLORADO': 'CO',\n",
    "    'CONN': 'CT', 'CONNECTICUT': 'CT',\n",
    "    'DEL': 'DE', 'DELAWARE': 'DE',\n",
    "    'FLA': 'FL', 'FLORIDA': 'FL',\n",
    "    'GA': 'GA', 'GEORGIA': 'GA',\n",
    "    'IDAHO': 'ID',\n",
    "    'ILL': 'IL', 'ILLINOIS': 'IL',\n",
    "    'IND': 'IN', 'INDIANA': 'IN',\n",
    "    'IOWA': 'IA',\n",
    "    'KAN': 'KS', 'KANSAS': 'KS',\n",
    "    'KY': 'KY', 'KENTUCKY': 'KY',\n",
    "    'LA': 'LA', 'LOUISIANA': 'LA',\n",
    "    'MAINE': 'ME',\n",
    "    'MD': 'MD', 'MARYLAND': 'MD',\n",
    "    'MASS': 'MA', 'MASSACHUSETTS': 'MA',\n",
    "    'MICH': 'MI', 'MICHIGAN': 'MI',\n",
    "    'MINN': 'MN', 'MINNESOTA': 'MN',\n",
    "    'MISS': 'MS', 'MISSISSIPPI': 'MS',\n",
    "    'MO': 'MO', 'MISSOURI': 'MO',\n",
    "    'MONT': 'MT', 'MONTANA': 'MT',\n",
    "    'NEBR': 'NE', 'NEBRASKA': 'NE',\n",
    "    'NEV': 'NV', 'NEVADA': 'NV',\n",
    "    'N H': 'NH', 'NEW HAMPSHIRE': 'NH',\n",
    "    'N J': 'NJ', 'NEW JERSEY': 'NJ',\n",
    "    'N M': 'NM', 'NEW MEXICO': 'NM',\n",
    "    'NY': 'NY', 'N Y': 'NY', 'NEW YORK': 'NY',\n",
    "    'N C': 'NC', 'NORTH CAROLINA': 'NC',\n",
    "    'N D': 'ND', 'NORTH DAKOTA': 'ND',\n",
    "    'OHIO': 'OH',\n",
    "    'OKLA': 'OK', 'OKLAHOMA': 'OK',\n",
    "    'OREG': 'OR', 'OREGON': 'OR',\n",
    "    'PENN': 'PA', 'PENNSYLVANIA': 'PA',\n",
    "    'R I': 'RI', 'RHODE ISLAND': 'RI',\n",
    "    'S C': 'SC', 'SOUTH CAROLINA': 'SC',\n",
    "    'S D': 'SD', 'SOUTH DAKOTA': 'SD',\n",
    "    'TENN': 'TN', 'TENNESSEE': 'TN',\n",
    "    'TEX': 'TX', 'TEXAS': 'TX',\n",
    "    'UTAH': 'UT',\n",
    "    'VT': 'VT', 'VERMONT': 'VT',\n",
    "    'VA': 'VA', 'VIRGINIA': 'VA',\n",
    "    'WASH': 'WA', 'WASHINGTON': 'WA',\n",
    "    'W VA': 'WV', 'WEST VIRGINIA': 'WV',\n",
    "    'WIS': 'WI', 'WISCONSIN': 'WI',\n",
    "    'WYO': 'WY', 'WYOMING': 'WY'\n",
    "}\n",
    "\n",
    "# Known city aliases\n",
    "city_aliases = {\n",
    "    'NYC': 'NEW YORK, NY',\n",
    "    'NY': 'NEW YORK, NY'\n",
    "}\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_place(value):\n",
    "    if pd.isnull(value) or value.strip() == '':\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "    # Fix known typos\n",
    "    value = re.sub(r'\\bHOEL\\b', 'HOTEL', value, flags=re.IGNORECASE)\n",
    "    value = re.sub(r\"ANDERTON'S\", \"ANDERTONS\", value, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove brackets, quotes, parentheses, question marks\n",
    "    value = re.sub(r'[\\[\\]\"\\']', '', value)\n",
    "    value = re.sub(r'[()]', '', value)\n",
    "    value = value.replace('?', '')\n",
    "\n",
    "    # Normalize commas and semicolons\n",
    "    value = re.sub(r'\\s*[,;]+\\s*', ', ', value).strip(',; ')\n",
    "\n",
    "    # Standardize state abbreviations\n",
    "    for old, new in state_abbrev_fixes.items():\n",
    "        value = re.sub(rf'\\b{old}\\b', new, value, flags=re.IGNORECASE)\n",
    "\n",
    "    # Replace known city aliases\n",
    "    for old, new in city_aliases.items():\n",
    "        value = re.sub(rf'\\b{old}\\b', new, value, flags=re.IGNORECASE)\n",
    "\n",
    "    # Deduplicate repeated segments (e.g., NEW YORK, NY, NEW YORK, NY)\n",
    "    parts = [p.strip() for p in value.split(',')]\n",
    "    seen = set()\n",
    "    cleaned_parts = []\n",
    "    for part in parts:\n",
    "        if part and part not in seen:\n",
    "            seen.add(part)\n",
    "            cleaned_parts.append(part)\n",
    "\n",
    "    return ', '.join(cleaned_parts).upper()\n",
    "\n",
    "# Apply cleaning function\n",
    "df['place_cleaned'] = df['place'].apply(clean_place)\n",
    "\n",
    "# ---- Clean 'sponsor' column ----\n",
    "def clean_sponsor(value):\n",
    "    if pd.isnull(value) or str(value).strip() == '':\n",
    "        return 'UNKNOWN'\n",
    "    value = str(value).strip().upper()\n",
    "    value = re.sub(r'[\\[\\]()\"\\']', '', value)\n",
    "    value = re.sub(r'\\s+', ' ', value)\n",
    "    return value\n",
    "\n",
    "df['sponsor_cleaned'] = df['sponsor'].apply(clean_sponsor)\n",
    "\n",
    "# ---- Clean 'event' column ----\n",
    "def clean_event(value):\n",
    "    if pd.isnull(value) or str(value).strip() == '':\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "    value = str(value).strip().upper()\n",
    "    value = re.sub(r'[\\[\\]()\"\\']', '', value)           # remove brackets and quotes\n",
    "    value = re.sub(r'[;:]+$', '', value)                # remove trailing punctuation\n",
    "\n",
    "    # Fix common typos using word boundaries to avoid unintended replacements\n",
    "    value = re.sub(r'\\bDINNE\\b', 'DINNER', value)\n",
    "\n",
    "    value = re.sub(r'\\s+', ' ', value)                  # normalize whitespace\n",
    "    return value\n",
    "\n",
    "df['event_cleaned'] = df['event'].apply(clean_event)\n",
    "\n",
    "# ---- Clean 'venue' column ----\n",
    "def clean_venue(value):\n",
    "    if pd.isnull(value) or str(value).strip() in [\"\", \"?\", \"[?]\", \"[POL?);\"]:\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "    value = str(value).upper().strip()\n",
    "\n",
    "    # Remove trailing semicolons and extra punctuation\n",
    "    value = re.sub(r'[^A-Z;, ]', '', value)   # keep letters and common separators\n",
    "    value = re.sub(r'\\s+', ' ', value)        # collapse multiple spaces\n",
    "    value = re.sub(r'[;,]+$', '', value)      # remove trailing punctuation\n",
    "    value = re.sub(r'[\\[\\](){}]', '', value)  # remove brackets/parentheses\n",
    "    value = value.strip(' ,;.')\n",
    "\n",
    "    # Normalize common variants\n",
    "    replacements = {\n",
    "        'COMMERCIAL': 'COMMERCIAL',\n",
    "        'COM': 'COMMERCIAL',\n",
    "        'COMMERCOA': 'COMMERCIAL',\n",
    "        'CMMERCIAL': 'COMMERCIAL',\n",
    "        'COMM': 'COMMERCIAL',\n",
    "        'COMM.': 'COMMERCIAL',\n",
    "        'COM.;': 'COMMERCIAL',\n",
    "        'GOVT': 'GOVERNMENT',\n",
    "        \"GOV'T\": 'GOVERNMENT',\n",
    "        \"GOV'T.\": 'GOVERNMENT',\n",
    "        'GOV.': 'GOVERNMENT',\n",
    "        'GOV': 'GOVERNMENT',\n",
    "        'SOC': 'SOCIAL',\n",
    "        'SOC;': 'SOCIAL',\n",
    "        'SOCIAL CLUB': 'SOCIAL',\n",
    "        'POLIT': 'POLITICAL',\n",
    "        'POL;': 'POLITICAL',\n",
    "        'POL': 'POLITICAL',\n",
    "        'RELIG;': 'RELIGIOUS',\n",
    "        'RELIG': 'RELIGIOUS',\n",
    "        'NAV': 'NAVAL',\n",
    "        'NAV.': 'NAVAL',\n",
    "        'NAVAL;': 'NAVAL',\n",
    "        'MIL;': 'MILITARY',\n",
    "        'MIL.': 'MILITARY',\n",
    "        'MIL': 'MILITARY',\n",
    "        'EDUC;': 'EDUCATIONAL',\n",
    "        'EDUC': 'EDUCATIONAL',\n",
    "        'EDUS': 'EDUCATIONAL',\n",
    "        'EDUCATIONAL;': 'EDUCATIONAL',\n",
    "        'PROF;': 'PROFESSIONAL',\n",
    "        'PROF': 'PROFESSIONAL',\n",
    "        'PROF.': 'PROFESSIONAL',\n",
    "        'PRO;': 'PROFESSIONAL',\n",
    "        'PATRIOTIC?': 'PATRIOTIC',\n",
    "        'PAT': 'PATRIOTIC',\n",
    "        'PATR': 'PATRON',\n",
    "        'PATR.': 'PATRON',\n",
    "        'PRIVATE PARTY': 'PRIVATE',\n",
    "        'PRIVATE;': 'PRIVATE',\n",
    "        'PRIVATE': 'PRIVATE'\n",
    "    }\n",
    "\n",
    "    for key, val in replacements.items():\n",
    "        if value.startswith(key):\n",
    "            return val\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "df['venue_cleaned'] = df['venue'].apply(clean_venue)\n",
    "\n",
    "# ---- Reorder new columns next to originals ----\n",
    "def move_next_to(df, original_col, cleaned_col):\n",
    "    cols = list(df.columns)\n",
    "    if original_col in cols and cleaned_col in cols:\n",
    "        cols.remove(cleaned_col)\n",
    "        cols.insert(cols.index(original_col) + 1, cleaned_col)\n",
    "    return df[cols]\n",
    "\n",
    "for orig, clean in [('place', 'place_cleaned'),\n",
    "                    ('sponsor', 'sponsor_cleaned'),\n",
    "                    ('event', 'event_cleaned'),\n",
    "                    ('venue', 'venue_cleaned')]:\n",
    "    df = move_next_to(df, orig, clean)\n",
    "\n",
    "# ---- Save the cleaned result ----\n",
    "df.to_csv(\"Menu_cleaned.csv\", index=False)\n",
    "print(\"Cleaned dataset saved as Menu_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa58cc4-66db-4444-ade1-ba566bfb828e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
